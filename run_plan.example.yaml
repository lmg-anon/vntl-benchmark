# List of planned runs
- title: "My Run" # Title of the run
  model: 
    # Specifies the backend service to use
    backend: "openai"

    # Host address for the backend service
    backend_host: "127.0.0.1:5000"

    # API key for authenticating with the backend
    backend_api_key: "<API_KEY>"

    # File path to the backend server executable, in case you want the script to run it.
    #backend_path: "C:\\llama.cpp\\server_cublas.exe"

    # Path to the model file
    #path: "C:\\llama.cpp\\models\\LLaMA2\\llama-2-13b-chat.ggmlv3.q5_K_M.bin"
  
  # Size of the context for the model
  context_size: 4096

  # Number of threads to use for the model
  thread_number: 5

  # Additional arguments for running the benchmark script
  extra_args: "--verbose --seed 3407"

# Yes, you can have more than one planned run!
#- title: "Run 2"
#  model:
#    backend: "openai"
#    backend_host: "127.0.0.1:5000"
#  context_size: 4096
#  thread_number: 5