# downloader:
#   repo: "lmg-anon/vntl-llama3-8b-gguf"
#   filters: "q8_0"
#   output: ".\\gguf"
#   #delete_after: true

backend:
  type: "openai"
  host: "http://127.0.0.1:5000"
  api_key: "17d6f6dbc646d8b572a17ab232cafc92"
  chat_endpoint: False

# run:
#   path: ".\\koboldcpp (6).exe"
#   arguments: "--model \".\\gguf\\vntl-llama3-8b-hf-q8_0.gguf\" --threads 5 --blasthreads 5 --contextsize 2048 --usecublas normal 0 --gpulayers 999 --highpriority --flashattention --nommap --multiuser 1"